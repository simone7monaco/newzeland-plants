{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "fern_species = pd.read_excel(\"Species list.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69956738f5c44eb6a207e493883f74c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "conditional_newline = lambda sp: '\\s*\\n?'.join(sp.split(' ')).replace('.', '\\.').replace('(', '\\(').replace(')', '\\)').replace('[', '\\[').replace(']', '\\]')\n",
    "sp_descriptions = pd.DataFrame()\n",
    "for fam in tqdm(fern_species.Family.unique()):\n",
    "    text = \"\"\n",
    "    with open(f\"descriptions/{fam}.pdf\", \"rb\") as pdf_file:\n",
    "        read_pdf = PdfReader(pdf_file)\n",
    "        for i, page in enumerate(read_pdf.pages):\n",
    "            if i < 5:\n",
    "                continue\n",
    "            tx = page.extract_text()\n",
    "            if tx.split(\"\\n\")[0].startswith('References'):\n",
    "                # print(f\"Breaking at page {i}\")\n",
    "                break\n",
    "            text += page.extract_text()\n",
    "    text = re.sub(r'[^\\S\\r\\n]+', ' ', text)\n",
    "\n",
    "    fam_species = fern_species[fern_species.Family.eq(fam)].Species.unique()\n",
    "    sp_dict = {}\n",
    "    for i, species in enumerate(fam_species):\n",
    "        species = species\n",
    "        if (cnt := len(re.findall(conditional_newline(species), text))) == 0:\n",
    "            print(f\"{fam} | {species} wrongly appearing (count: {cnt})\")\n",
    "            foo\n",
    "        # start = text.find(species)\n",
    "        # start is the first character of the species name assuming to find it in the text\n",
    "        # with potentially some '\\n' characters in between\n",
    "        start = re.search(conditional_newline(species), text).start()\n",
    "        end = [re.search(conditional_newline(sp), text).start() for sp in fam_species]\n",
    "        end = min([e for e in end if e and e > start] + [len(text)])\n",
    "        name_sp = species.split(')')[0] + ')'\n",
    "        if name_sp not in sp_dict.keys():\n",
    "            sp_dict[name_sp] = text[start:end]\n",
    "        else:\n",
    "            sp_dict[name_sp] += '\\n' + text[start:end]\n",
    "\n",
    "    sp_descriptions = pd.concat([sp_descriptions, pd.DataFrame(sp_dict.items(), columns=['Species', 'Description']).assign(Family=fam)], ignore_index=True)\n",
    "\n",
    "\n",
    "def desc_to_sections(desc):\n",
    "    \"\"\"\n",
    "    Split the description into sections:\n",
    "    \"Etymology\", \"Vernacular name\", \"Distribution\", \"Altitudinal range\", \"Biostatus\", \"Habitat\", \"First record \", \"Recognition \", \"Cytology\", \"Hybridisation\", \"Notes \"\n",
    "    not all the sections will be present in all descriptions, if present, they start with the section name followed by a colon, up to the next named section or the end of the description\n",
    "    \"\"\"\n",
    "    sections = [\"Etymology\", \"Vernacular name\", \"Distribution\", \"Altitudinal range\", \"Biostatus\", \"Habitat\", \"First record\", \"Recognition\", \"Cytology\", \"Hybridisation\", \"Notes\"]\n",
    "    section_dict = {}\n",
    "    for i, section in enumerate(sections):\n",
    "        if i == len(sections) - 1:\n",
    "            section_dict[section] = desc\n",
    "        else:\n",
    "            start = re.search(fr\"{section}s?:\", desc)\n",
    "            start = start.end() if start else -1\n",
    "            if start == -1:\n",
    "                continue\n",
    "            end = re.search(fr\"{sections[i+1]}s?:\", desc)\n",
    "            end = end.start() if end else -1\n",
    "\n",
    "            this_desc = desc[start:end].strip()\n",
    "\n",
    "            section_dict[section] = re.sub(r'\\n+', ' ', this_desc.strip())\n",
    "    return pd.Series(section_dict)\n",
    "\n",
    "extra = sp_descriptions.Description.apply(desc_to_sections)  \n",
    "sp_descriptions = pd.concat([sp_descriptions, extra], axis=1).drop(columns='Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_descriptions.to_excel(\"fern_descriptions.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_descriptions = pd.read_excel(\"fern_descriptions.xlsx\").set_index('Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_features_df = pd.read_excel(\"../Words before and after traits_v2.xlsx\", sheet_name=\"FernPrecedingWords\")\n",
    "extra_features_df = extra_features_df[\n",
    "    :extra_features_df[extra_features_df.Rhizome.str.startswith('Sentences that talk a', na=False)].index[0]\n",
    "    ].map(lambda s:s.lower().strip() if type(s) == str else s)\n",
    "\n",
    "extra_features = extra_features_df.to_dict('list')\n",
    "extra_features = {k.title().replace(' ', ''): [x for x in v if str(x) != 'nan'] for k, v in extra_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = '[m|c|d|µ]?m'\n",
    "number = r\"(\\d+\\.?\\d*)\"\n",
    "full_regex = rf\"(({number}\\s?-\\s?)?{number})?({number}\\s?-\\s?)?{number}\\s*{unit}(-wide)?(-long)?\"\n",
    "full_regex = full_regex + r'(?=[\\s\\.,;])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((\\d+\\.?\\d*)\\s?-\\s?)?(\\d+\\.?\\d*))?((\\d+\\.?\\d*)\\s?-\\s?)?(\\d+\\.?\\d*)\\s*[m|c|d|µ]?m(-wide)?(-long)?(?=[\\s\\.,;])\n"
     ]
    }
   ],
   "source": [
    "print(full_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "anomalies = set() # species with anomalies\n",
    "\n",
    "def extract_features(i, feats:list):\n",
    "\tfeatures = {}\n",
    "\tfor feat in feats:\n",
    "\t\tif len(feat) < 1:\n",
    "\t\t\tcontinue\n",
    "\t\tfeat = feat.replace(',', ' ')\n",
    "\t\tmeasures = re.finditer(full_regex, feat)\n",
    "\t\tfor measure in measures:\n",
    "\t\t\tfound = None\n",
    "\t\t\tfor key, values in extra_features.items():\n",
    "\n",
    "\t\t\t\tfeat = feat[:-1] if feat[-1] in ['.', ';'] else feat # remove any of .; at the end of the sentence\n",
    "\t\t\t\tmatched_word = list(re.finditer( r'\\b('+ '|'.join([w for w in set(values)]) + r')\\b', feat.lower()))\n",
    "\t\t\t\t\n",
    "\t\t\t\tif any(matched_word):\t\n",
    "\t\t\t\t\tif key != 'Stature': # TODO: Caso up to 3m, petiole 2mm???\n",
    "\t\t\t\t\t\tmatched_word = [w for w in matched_word if w.span()[0] < measure.span()[0]]\n",
    "\t\t\t\t\t\tif not any(matched_word):\n",
    "\t\t\t\t\t\t\tcontinue # if not stature and measure appears before the word, skip\n",
    "\t\t\t\t\tmatched_word = sorted(matched_word, key=lambda word: word.span()[1] - measure.span()[0])[0]\n",
    "\n",
    "\t\t\t\t\tthis_distance = abs(matched_word.span()[1] - measure.span()[0])\n",
    "\t\t\t\t\t# this_distance = abs(word_match_position - measure_position)\n",
    "\t\t\t\t\tif found:\n",
    "\t\t\t\t\t\tif (any([w in feat.lower() for w in ['achene', 'cypsela']]) and {key, found[0]} == {'FruitSize', 'SeedSize'}) or\\\n",
    "\t\t\t\t\t\t   (any([w in feat.lower() for w in ['stigma-style']]) and {key, found[0]} == {'StigmaSize', 'StyleSize'}) or\\\n",
    "\t\t\t\t\t\t   (any([w in feat.lower() for w in ['floret']]) and {key, found[0]} == {'RayFloretsSize', 'DiskFloretSize'}):\n",
    "\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\t\t# print(f'OK>> Multiple features found ({found}, {key}) in \"{feat}\"')\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tif this_distance >= found[1]:\n",
    "\t\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t# print(found, key, matched_word, measure)\n",
    "\t\t\t\t\t\t\t\tfeatures[found[0]].remove(found[2])\n",
    "\t\t\t\t\t\t\tanomalies.add(i)\n",
    "\t\t\t\t\tfound = (key, this_distance, measure.group().strip())\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif key in features:\n",
    "\t\t\t\t\t\tfeatures[key].append(measure.group().strip())\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tfeatures[key] = [measure.group().strip()]\n",
    "\treturn pd.Series(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_preprocessing(s):\n",
    "\ts = s.replace('\\xa0', ' ').replace('×', 'x').replace('–', '-').replace('·', '.') # remove non-breaking space and replace multiplication sign with x\n",
    "\ts = re.sub(r'(?<=xcluding)\\s+[\\w-]+', ' ', s) # remove each word following \"excluding\" (Mericarps (excluding style) 2.5-3.0 mm should point to \"Mericarps\")\n",
    "\ts = re.sub(fr'-?\\(-?{number}-?\\)-?', '', s) # remove all parentesis surrounding a number and the number inside (e.g. (-1.5) --> **)\n",
    "\t# s = s.replace('--', '-').replace('-.', '-').replace('..', '.')\n",
    "\t# s = s.replace('(', '').replace(')', '')\n",
    "\t# s = re.sub(r'\\s(c|ca|o)\\.', ' foo ', s) # remove all ' c.'\n",
    "\ts = re.sub(r'(?<=\\d)\\s+(?=[cmd]?m)', '', s) # remove all spaces before measures (mm, cm, dm, m, these strings only if padded by a space)\n",
    "\ts = re.sub('m long;?', 'm-long', s) # remove space between measure and \"long\" (e.g. 2 mm long --> 2 mm-long)\n",
    "\ts = re.sub('m wide;?', 'm-wide', s) # remove space between measure and \"wide\" (e.g. 2 mm wide --> 2 mm-wide)\n",
    "\ts = re.sub(r'\\s*-\\s*', '-', s) # remove spaces around hyphens\n",
    "\ts = re.sub(r'(?<=\\d)\\s*\\.(?=\\d)', '.', s) # remove spaces before dot if followed and preceded by a number\n",
    "\ts = re.sub(r'(?<=\\s)\\.(?=\\d)', '0.', s) # add a 0 before a dot if it is preceded by a space and a \"not number\" and followed by a number (e.g. foo .5 --> foo 0.5)\n",
    "\t# s = re.sub(r'(?<=[\\dm])\\s*x\\s*(?=\\d+)', 'x', s) # remove spaces around x in formulas\n",
    "\ts = re.sub(rf'(;\\s*)({full_regex})', r' \\2', s) # point to any ';' preceding a measure (full_regex) and remove it, without removing the measure\n",
    "\t# now all measures are supposed to have no spaces between number and unit and spaces around them\n",
    "\n",
    "\t# s = re.sub(rf'(?<=\\d{unit})(\\s*long,?\\s*)(?={number}{unit})', r'x', s) # remove any 'long' after a measure (\"2 mm long X 3 mm wide\" --> \"2 mm x 3 mm wide\")\n",
    "\t# s = re.sub(rf'(?<=\\d)([m|c|d]m|m(?!m))(?!x)', r'\\1 ', s) # fix situation in which a measure is not followed by a space, in the case, add that space\n",
    "\t# s = re.sub(r'(?<![\\d\\sx\\.-])(\\d)', r' \\1', s) # fix the situation in which a measure (the whole number and measure) is not preceded by a space. In the case, add a space before the measure\n",
    "\t# s = re.sub(rf'(?<=\\s)-(?=\\d)', '', s) # remove '-' at the beginning of a measure (e.g. -1.5 --> 1.5)\n",
    "\t# s = re.sub(r'(?<=\\d\\.\\d+)(\\.\\d?)', '', s) # fix the error in which there is a doubled dot in a number (e.g. 1.5.2), in the case, remove the second dot and the eventual numbers after it\n",
    "\t# s = re.sub(r'(?<=[a-ln-z])-(?=\\d)', ' ', s) # remove all '-' preceded by a letter (different from m) and followed by a number (e.g. to-250mm --> to 250mm)\n",
    "\t# s = re.sub(r'(?<![a-z])(l|I)(?=[\\s\\.-]|\\d)', '1', s) # replace all 'l' or \"I\" characters which should be '1' (e.g. l.5 --> 1.5). This should be followed by a space, a dot, a hyphen, or a number and not preceded by a letter\n",
    "\treturn s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_833904/1901678600.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  features = features.applymap(lambda x: '; '.join(x) if not isinstance(x, float) else x)\n"
     ]
    }
   ],
   "source": [
    "features = sp_descriptions.Etymology.fillna('') + ' ' + sp_descriptions['Vernacular name'].fillna('')\n",
    "features = features.apply(string_preprocessing).str.split(r'\\s\\.').reset_index().apply(lambda x: extract_features(x.Species, x[0]), axis=1)\n",
    "features = features.map(lambda x: '; '.join(x) if not isinstance(x, float) else x)\n",
    "features.index = sp_descriptions.index\n",
    "features[features.notna().sum(axis=1) > 0].to_csv('processed_features_fern.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "processed_path = Path.cwd().parent / \"Felci/processed_features_fern.csv\"\n",
    "species = pd.read_excel(Path.cwd().parent / \"Felci/fern_descriptions.xlsx\").set_index('Species')\n",
    "species['Features'] = species.Etymology.fillna('') + ' ' + species['Vernacular name'].fillna('')\n",
    "\n",
    "\n",
    "processed_features = species.Features.apply(string_preprocessing).str.split(r'\\s\\.').reset_index().apply(lambda x: extract_features(x.Species, x.Features), axis=1)\n",
    "processed_features = processed_features.map(lambda x: '; '.join(x) if not isinstance(x, float) else x)\n",
    "processed_features.index = species.index\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FertileFronds': 0,\n",
       " 'Frond': 1,\n",
       " 'Habit**': 2,\n",
       " 'Laminae': 3,\n",
       " 'PrimaryPinnae': 4,\n",
       " 'Rachis': 5,\n",
       " 'Rhizome': 6,\n",
       " 'SecondaryPinnae': 7,\n",
       " 'Sori': 8,\n",
       " 'Sporangia': 9,\n",
       " 'Spores': 10,\n",
       " 'SterileFronds': 11,\n",
       " 'Stipe': 12,\n",
       " 'TertiaryPinnae': 13,\n",
       " 'Venation*': 14,\n",
       " 'null': '#808080'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{feat: i for i, feat in enumerate(processed_features.columns)} | {'null': '#808080'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anemia phyllitidis (L.)</td>\n",
       "      <td>[From the Greek phyllitidis (like Phyllitis )....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athyrium filix-femina (L.)</td>\n",
       "      <td>[From the Latin filix (fern) and femina (femal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Athyrium otophorum (Miq.)</td>\n",
       "      <td>[From the Greek otos (ear) and phorus (bearing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deparia petersenii subsp. congrua (Brack.)</td>\n",
       "      <td>[From the Latin congruus (agreeable). Rhizomes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deparia petersenii (Kunze)</td>\n",
       "      <td>[From the Greek diplasios (double), a referenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Cyclosorus interruptus (Willd.)</td>\n",
       "      <td>[From the Latin interruptus (interrupted). Rhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Macrothelypteris torresiana (Gaudich.)</td>\n",
       "      <td>[Named in honour of Luís Vaz de Torres (b. 156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Pakau pennigera (G.Forst.)</td>\n",
       "      <td>[From the Latin pennigerus (with feathery leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Pseudophegopteris aurita (Hook.)</td>\n",
       "      <td>[From the Latin auritus (long-eared), a refere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Thelypteris confluens (Thunb.)</td>\n",
       "      <td>[From the Latin confluens (running together). ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Species  \\\n",
       "0                       Anemia phyllitidis (L.)   \n",
       "1                    Athyrium filix-femina (L.)   \n",
       "2                     Athyrium otophorum (Miq.)   \n",
       "3    Deparia petersenii subsp. congrua (Brack.)   \n",
       "4                    Deparia petersenii (Kunze)   \n",
       "..                                          ...   \n",
       "265             Cyclosorus interruptus (Willd.)   \n",
       "266      Macrothelypteris torresiana (Gaudich.)   \n",
       "267                  Pakau pennigera (G.Forst.)   \n",
       "268            Pseudophegopteris aurita (Hook.)   \n",
       "269              Thelypteris confluens (Thunb.)   \n",
       "\n",
       "                                              Features  \n",
       "0    [From the Greek phyllitidis (like Phyllitis )....  \n",
       "1    [From the Latin filix (fern) and femina (femal...  \n",
       "2    [From the Greek otos (ear) and phorus (bearing...  \n",
       "3    [From the Latin congruus (agreeable). Rhizomes...  \n",
       "4    [From the Greek diplasios (double), a referenc...  \n",
       "..                                                 ...  \n",
       "265  [From the Latin interruptus (interrupted). Rhi...  \n",
       "266  [Named in honour of Luís Vaz de Torres (b. 156...  \n",
       "267  [From the Latin pennigerus (with feathery leav...  \n",
       "268  [From the Latin auritus (long-eared), a refere...  \n",
       "269  [From the Latin confluens (running together). ...  \n",
       "\n",
       "[270 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species.Features.apply(string_preprocessing).str.split(r'\\s\\.').reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
