{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "fern_species = pd.read_excel(\"Species list.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69956738f5c44eb6a207e493883f74c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "conditional_newline = lambda sp: '\\s*\\n?'.join(sp.split(' ')).replace('.', '\\.').replace('(', '\\(').replace(')', '\\)').replace('[', '\\[').replace(']', '\\]')\n",
    "sp_descriptions = pd.DataFrame()\n",
    "for fam in tqdm(fern_species.Family.unique()):\n",
    "    text = \"\"\n",
    "    with open(f\"descriptions/{fam}.pdf\", \"rb\") as pdf_file:\n",
    "        read_pdf = PdfReader(pdf_file)\n",
    "        for i, page in enumerate(read_pdf.pages):\n",
    "            if i < 5:\n",
    "                continue\n",
    "            tx = page.extract_text()\n",
    "            if tx.split(\"\\n\")[0].startswith('References'):\n",
    "                # print(f\"Breaking at page {i}\")\n",
    "                break\n",
    "            text += page.extract_text()\n",
    "    text = re.sub(r'[^\\S\\r\\n]+', ' ', text)\n",
    "\n",
    "    fam_species = fern_species[fern_species.Family.eq(fam)].Species.unique()\n",
    "    sp_dict = {}\n",
    "    for i, species in enumerate(fam_species):\n",
    "        species = species\n",
    "        if (cnt := len(re.findall(conditional_newline(species), text))) == 0:\n",
    "            print(f\"{fam} | {species} wrongly appearing (count: {cnt})\")\n",
    "            foo\n",
    "        # start = text.find(species)\n",
    "        # start is the first character of the species name assuming to find it in the text\n",
    "        # with potentially some '\\n' characters in between\n",
    "        start = re.search(conditional_newline(species), text).start()\n",
    "        end = [re.search(conditional_newline(sp), text).start() for sp in fam_species]\n",
    "        end = min([e for e in end if e and e > start] + [len(text)])\n",
    "        name_sp = species.split(')')[0] + ')'\n",
    "        if name_sp not in sp_dict.keys():\n",
    "            sp_dict[name_sp] = text[start:end]\n",
    "        else:\n",
    "            sp_dict[name_sp] += '\\n' + text[start:end]\n",
    "\n",
    "    sp_descriptions = pd.concat([sp_descriptions, pd.DataFrame(sp_dict.items(), columns=['Species', 'Description']).assign(Family=fam)], ignore_index=True)\n",
    "\n",
    "\n",
    "def desc_to_sections(desc):\n",
    "    \"\"\"\n",
    "    Split the description into sections:\n",
    "    \"Etymology\", \"Vernacular name\", \"Distribution\", \"Altitudinal range\", \"Biostatus\", \"Habitat\", \"First record \", \"Recognition \", \"Cytology\", \"Hybridisation\", \"Notes \"\n",
    "    not all the sections will be present in all descriptions, if present, they start with the section name followed by a colon, up to the next named section or the end of the description\n",
    "    \"\"\"\n",
    "    sections = [\"Etymology\", \"Vernacular name\", \"Distribution\", \"Altitudinal range\", \"Biostatus\", \"Habitat\", \"First record\", \"Recognition\", \"Cytology\", \"Hybridisation\", \"Notes\"]\n",
    "    section_dict = {}\n",
    "    for i, section in enumerate(sections):\n",
    "        if i == len(sections) - 1:\n",
    "            section_dict[section] = desc\n",
    "        else:\n",
    "            start = re.search(fr\"{section}s?:\", desc)\n",
    "            start = start.end() if start else -1\n",
    "            if start == -1:\n",
    "                continue\n",
    "            end = re.search(fr\"{sections[i+1]}s?:\", desc)\n",
    "            end = end.start() if end else -1\n",
    "\n",
    "            this_desc = desc[start:end].strip()\n",
    "\n",
    "            section_dict[section] = re.sub(r'\\n+', ' ', this_desc.strip())\n",
    "    return pd.Series(section_dict)\n",
    "\n",
    "extra = sp_descriptions.Description.apply(desc_to_sections)  \n",
    "sp_descriptions = pd.concat([sp_descriptions, extra], axis=1).drop(columns='Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_descriptions.to_excel(\"fern_descriptions.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_descriptions = pd.read_excel(\"fern_descriptions.xlsx\").set_index('Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_features_df = pd.read_excel(\"../Words before and after traits_v2.xlsx\", sheet_name=\"FernPrecedingWords\")\n",
    "extra_features_df = extra_features_df[\n",
    "    :extra_features_df[extra_features_df.Rhizome.str.startswith('Sentences that talk a', na=False)].index[0]\n",
    "    ].map(lambda s:s.lower().strip() if type(s) == str else s)\n",
    "\n",
    "extra_features = extra_features_df.to_dict('list')\n",
    "extra_features = {k.title().replace(' ', ''): [x for x in v if str(x) != 'nan'] for k, v in extra_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = '[m|c|d|μ]?m'\n",
    "number = r\"(\\d+\\.?\\d*)\"\n",
    "full_regex = rf\"(({number}\\s?-\\s?)?{number})?({number}\\s?-\\s?)?{number}\\s*{unit}(-wide)?(-long)?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "anomalies = set() # species with anomalies\n",
    "\n",
    "def extract_features(i, feats:list):\n",
    "\tfeatures = {}\n",
    "\tfor feat in feats:\n",
    "\t\tif len(feat) < 1:\n",
    "\t\t\tcontinue\n",
    "\t\tfeat = feat.replace(',', ' ')\n",
    "\t\tmeasures = re.finditer(full_regex, feat)\n",
    "\t\tfor measure in measures:\n",
    "\t\t\tfound = None\n",
    "\t\t\tfor key, values in extra_features.items():\n",
    "\t\t\t\tif key.startswith('Habit'):\n",
    "\t\t\t\t\t# categorical feature, append all the values present in feat\n",
    "\t\t\t\t\tfeatures['Habit'] = ';'.join([v for v in values if v.lower() in re.split(r'[^\\w]', feat.lower())])\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tif key.startswith('Venation'):\n",
    "\t\t\t\t\t# categorical feature, store feat as it is\n",
    "\t\t\t\t\t# features['Venation'] = feat\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\tfeat = feat[:-1] if feat[-1] in ['.', ';'] else feat # remove any of .; at the end of the sentence\n",
    "\t\t\t\tmatched_word = list(re.finditer( r'\\b('+ '|'.join([w for w in set(values)]) + r')\\b', feat.lower()))\n",
    "\t\t\t\t\n",
    "\t\t\t\tif any(matched_word):\n",
    "\t\t\t\t# \"*Secondary* pinnae decreasing very gradually in length along each ~primary~ pinna to the distal end...\" is supposed to be Secondary\n",
    "\t\t\t\t\tif key == 'Laminae' and 'primary' in feat.lower() and len(features.get('Laminae', [])) >= 2:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\tif key == 'PrimaryPinnae' and 'secondary' in feat.lower() and len(features.get('PrimaryPinnae', [])) >= 2:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\tmatched_word = [w for w in matched_word if w.span()[0] < measure.span()[0]]\n",
    "\t\t\t\t\tif not any(matched_word):\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\tmatched_word = sorted(matched_word, key=lambda word: word.span()[1] - measure.span()[0])[0]\n",
    "\t\t\t\t\tthis_distance = abs(matched_word.span()[1] - measure.span()[0])\n",
    "\t\t\t\t\t# this_distance = abs(word_match_position - measure_position)\n",
    "\n",
    "\t\t\t\t\tif key in ['Stipe', 'Laminae']:\n",
    "\t\t\t\t\t\thair_or_scale_position = list(re.finditer(r'(hair|scale)', feat.lower()))\n",
    "\t\t\t\t\t\t# C1: Se nella frase dello stipe trovi le keyword \"hair\", \"hairs\", \"scale\", \"scales\", i valori dopo queste keyword vanno ignorati.\n",
    "\t\t\t\t\t\tif any(hair_or_scale_position) and hair_or_scale_position[0].start() < measure.start():\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\tif found:\n",
    "\t\t\t\t\t\tif (any([w in feat.lower() for w in ['achene', 'cypsela']]) and {key, found[0]} == {'FruitSize', 'SeedSize'}) or\\\n",
    "\t\t\t\t\t\t   (any([w in feat.lower() for w in ['stigma-style']]) and {key, found[0]} == {'StigmaSize', 'StyleSize'}) or\\\n",
    "\t\t\t\t\t\t   (any([w in feat.lower() for w in ['floret']]) and {key, found[0]} == {'RayFloretsSize', 'DiskFloretSize'}):\n",
    "\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\t\t# print(f'OK>> Multiple features found ({found}, {key}) in \"{feat}\"')\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tif this_distance >= found[1]:\n",
    "\t\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\t\t\tfeatures[found[0]].remove(found[2])\n",
    "\t\t\t\t\t\t\tanomalies.add(i)\n",
    "\n",
    "\t\t\t\t\tfound = (key, this_distance, measure.group())\n",
    "\t\t\t\t\tif key in features:\n",
    "\t\t\t\t\t\tfeatures[key].append(measure.group())\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tfeatures[key] = [measure.group()]\n",
    "\treturn pd.Series(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_preprocessing(s):\n",
    "\ts = s.replace('\\xa0', ' ').replace('×', 'x').replace('–', '-').replace('·', '.') # remove non-breaking space and replace multiplication sign with x\n",
    "\ts = re.sub(r'(?<=xcluding)\\s+[\\w-]+', ' ', s) # remove each word following \"excluding\" (Mericarps (excluding style) 2.5-3.0 mm should point to \"Mericarps\")\n",
    "\ts = re.sub(fr'-?\\(-?{number}-?\\)-?', '', s) # remove all parentesis surrounding a number and the number inside (e.g. (-1.5) --> **)\n",
    "\t# s = s.replace('--', '-').replace('-.', '-').replace('..', '.')\n",
    "\t# s = s.replace('(', '').replace(')', '')\n",
    "\t# s = re.sub(r'\\s(c|ca|o)\\.', ' foo ', s) # remove all ' c.'\n",
    "\ts = re.sub(rf'(?<=\\d)\\s+(?={unit})', '', s) # remove all spaces before measures (mm, cm, dm, m, these strings only if padded by a space)\n",
    "\ts = re.sub('m long;?', 'm-long', s) # remove space between measure and \"long\" (e.g. 2 mm long --> 2 mm-long)\n",
    "\ts = re.sub('m wide;?', 'm-wide', s) # remove space between measure and \"wide\" (e.g. 2 mm wide --> 2 mm-wide)\n",
    "\ts = re.sub(r'\\s*-\\s*', '-', s) # remove spaces around hyphens\n",
    "\ts = re.sub(r'(?<=\\d)\\s*\\.(?=\\d)', '.', s) # remove spaces before dot if followed and preceded by a number\n",
    "\ts = re.sub(r'(?<=\\s)\\.(?=\\d)', '0.', s) # add a 0 before a dot if it is preceded by a space and a \"not number\" and followed by a number (e.g. foo .5 --> foo 0.5)\n",
    "\t# s = re.sub(r'(?<=[\\dm])\\s*x\\s*(?=\\d+)', 'x', s) # remove spaces around x in formulas\n",
    "\ts = re.sub(rf'(;\\s*)({full_regex})', r' \\2', s) # point to any ';' preceding a measure (full_regex) and remove it, without removing the measure\n",
    "\treturn s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Stipes 35-480mm  blackish-brown proximally  yellow-brown or rarely red-brown distally; bearing multicellular pale brown hairs up to 0.5mm-long  and narrowly ovate  pale to dark brown scales up to 9mm-long and 2.5mm-wide\n",
      " Rachises yellow-brown or rarely red-brown  becoming green distally  winged distally  adaxially grooved  bearing multicellular hairs up to 0.5mm-long  and scales up to 1.5mm-long hairs more abundant distally\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rhizome</th>\n",
       "      <th>Habit</th>\n",
       "      <th>Stipe</th>\n",
       "      <th>Frond</th>\n",
       "      <th>Unnamed:17</th>\n",
       "      <th>Rachis</th>\n",
       "      <th>Laminae</th>\n",
       "      <th>PrimaryPinnae</th>\n",
       "      <th>SecondaryPinnae</th>\n",
       "      <th>Sori</th>\n",
       "      <th>Indusia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[260mm-long, 2.5-7mm, 4-6mm-long, 0.8-2mm-wide...</td>\n",
       "      <td></td>\n",
       "      <td>[5-40mm, 35-480mm]</td>\n",
       "      <td>[180-910mm-long]</td>\n",
       "      <td>[0.5mm-long, 9mm-long, 2.5mm-wide, 1mm-long, 1...</td>\n",
       "      <td>[0.5mm-long, 1.5mm-long]</td>\n",
       "      <td>[115-510mm-long, 40-270mm-wide]</td>\n",
       "      <td>[20-195mm-long, 10-75mm-wide, 1mm]</td>\n",
       "      <td>[5-40mm-long, 3-10mm-wide]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1-3mm-long]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Rhizome Habit  \\\n",
       "0  [260mm-long, 2.5-7mm, 4-6mm-long, 0.8-2mm-wide...         \n",
       "\n",
       "                Stipe             Frond  \\\n",
       "0  [5-40mm, 35-480mm]  [180-910mm-long]   \n",
       "\n",
       "                                          Unnamed:17  \\\n",
       "0  [0.5mm-long, 9mm-long, 2.5mm-wide, 1mm-long, 1...   \n",
       "\n",
       "                     Rachis                          Laminae  \\\n",
       "0  [0.5mm-long, 1.5mm-long]  [115-510mm-long, 40-270mm-wide]   \n",
       "\n",
       "                        PrimaryPinnae             SecondaryPinnae Sori  \\\n",
       "0  [20-195mm-long, 10-75mm-wide, 1mm]  [5-40mm-long, 3-10mm-wide]   []   \n",
       "\n",
       "        Indusia  \n",
       "0  [1-3mm-long]  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = sp_descriptions.Etymology.fillna('') + ' ' + sp_descriptions['Vernacular name'].fillna('')\n",
    "# delimiter any of '. ', '.\\n' and similar (all the dots not followed by numbers and not preceded by ' c', enforced with a negative lookbehind)\n",
    "delimiter = r'(?<! c)\\.(?!\\d)'\n",
    "tmp = features.apply(string_preprocessing).str.split(delimiter)\n",
    "tmp[tmp.index.str.contains('Deparia petersenii subsp')].reset_index().apply(lambda x: extract_features(x.Species, x[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sp_descriptions.Etymology.fillna('') + ' ' + sp_descriptions['Vernacular name'].fillna('')\n",
    "# delimiter any of '. ', '.\\n' and similar (all the dots not followed by numbers and not preceded by ' c', enforced with a negative lookbehind)\n",
    "delimiter = r'(?<! c)\\.(?!\\d)'\n",
    "features = features.apply(string_preprocessing).str.split(delimiter).reset_index().apply(lambda x: extract_features(x.Species, x[0]), axis=1)\n",
    "features = features.map(lambda x: '; '.join(x) if not isinstance(x, float) else x)\n",
    "features.index = sp_descriptions.index\n",
    "features[features.notna().sum(axis=1) > 0].to_csv('processed_features_fern.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLaminae\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrimaryPinnae\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSecondaryPinnae\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessFeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/frame.py:10034\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10022\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10024\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10025\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10026\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10032\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10033\u001b[0m )\n\u001b[0;32m> 10034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/apply.py:963\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 963\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/apply.py:979\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 979\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    981\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    982\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    983\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[63], line 30\u001b[0m, in \u001b[0;36mprocessFeat\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     28\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries(m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrange_to_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[63], line 6\u001b[0m, in \u001b[0;36mrange_to_num\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrange_to_num\u001b[39m(s):\n\u001b[0;32m----> 6\u001b[0m \tmetric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinditer\u001b[49m\u001b[43m(\u001b[49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m \tvalue \u001b[38;5;241m=\u001b[39m s[:metric\u001b[38;5;241m.\u001b[39mstart()]\n\u001b[1;32m      8\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m value:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/re.py:247\u001b[0m, in \u001b[0;36mfinditer\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinditer\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return an iterator over all non-overlapping matches in the\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m    string.  For each match, the iterator returns a Match object.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinditer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "features[['Laminae', 'PrimaryPinnae', 'SecondaryPinnae']].apply(processFeat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".5*(115+510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "long    312.5\n",
       "wide    155.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pint\n",
    "ureg = pint.UnitRegistry()\n",
    "\n",
    "def range_to_num(s):\n",
    "\tmetric = next(re.finditer(unit, s))\n",
    "\tvalue = s[:metric.start()]\n",
    "\tif '-' in value:\n",
    "\t\tvalue = np.array(value.split('-')).astype(float).mean()\n",
    "\telse:\n",
    "\t\tvalue = float(value)\n",
    "\t# return ureg.Quantity(value, metric.group())\n",
    "\treturn value\n",
    "\n",
    "\n",
    "s = '115-510mm-long; 40-270mm-wide;...'\n",
    "def processFeat(s:str):\n",
    "\t\"\"\"\n",
    "\tif wide and long are in s, split the string keeing the first 2 occurrences having wide and long\n",
    "\t\"\"\"\n",
    "\tif 'wide' in s and 'long' in s:\n",
    "\t\tslist = s.split(';')\n",
    "\t\tlong = [x.split('-long')[0].strip() for x in slist if 'long' in x][0]\n",
    "\t\twide = [x.split('-wide')[0].strip() for x in slist if 'wide' in x][0]\n",
    "\t\tm = (long, wide)\n",
    "\n",
    "\t\tm = {k: range_to_num(x) for x, k in zip(m, ['long', 'wide'])}\n",
    "\t\treturn pd.Series(m)\n",
    "\telse:\n",
    "\t\treturn range_to_num(s)\n",
    "\t\n",
    "processFeat(s)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
