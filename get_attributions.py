import pytorch_lightning as pl
from models import TraitsPredictor
from loader import FernDataset, NormalizeFeatures, data_split, NZData
from pathlib import Path
import torch
import numpy as np
from torch_geometric.data import Batch
from torch_geometric.utils import to_dense_batch
import pandas as pd
from tqdm import trange

from captum.attr import IntegratedGradients
from argparse import Namespace

args = Namespace(
    gnn_module='GATv2Conv',
    hidden_channels=128,
    num_layers=3,
    dropout=0.0,
)

# device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')
device = torch.device('cpu')
seed = 42
pl.seed_everything(seed)
torch.cuda.manual_seed(seed)
norm_transform = NormalizeFeatures()
dataset = FernDataset(Path('data/Ferns'), transform=norm_transform)

space_cols = ['lon_1', 'lon_2', 'lat_1', 'lat_2'] +\
             dataset.load_complete('climatic layers').columns.tolist() + \
             dataset.load_complete('population density and elevation layer').columns.tolist() + \
             dataset.load_complete('Soil NZ layers').columns.tolist()

Attr_Species = pd.DataFrame()
Attr_Spatial = pd.DataFrame()

for k in trange(5):
    data = dataset[0]
    train_data, test_data = data_split(data, k=k, seed=seed)
    model = TraitsPredictor(in_traits=data.species_x.size(1), in_phylo=data.species_x_phylo.size(1), 
                            in_space=data.spatial_global_data.size(1), out_channels=data.species_y.size(1), 
                            hidden_channels=args.hidden_channels, num_layers=args.num_layers,
                            dropout=.1, gnn_module=args.gnn_module)

    model_weight_path = sorted(Path.cwd().glob(f'best_model*{k}.pth'), reverse=True)[0]
    model_weight = torch.load(model_weight_path, weights_only=False)
    model.load_state_dict(model_weight)
    model = model.to(device)
    model.eval()

    data = data.to(device)
    test_data = test_data.to(device)
    test_species = np.array(test_data.species_names)[test_data.test_mask.cpu()]

    def forward_space_fn(x_spatial_input, species_idx=None, out_idx=0):
        virtual_batch = x_spatial_input.size(0) // test_data.spatial_num_nodes
        # handle virtual batches generated by captum
        data_exp = Batch.from_data_list([test_data] * virtual_batch, follow_batch=['species_x', 'spatial_x'])
        
        data_exp = data_exp.to(device)

        data_exp.spatial_global_data = x_spatial_input[:, :data_exp.spatial_global_data.size(1)]
        data_exp.spatial_x = x_spatial_input[:, data_exp.spatial_global_data.size(1):]

        out = model(data_exp)
        if species_idx is None:
            species_idx = torch.arange(data_exp.species_num_nodes, device=out.device)
        if virtual_batch > 1:
            out, _ = to_dense_batch(out, batch=data_exp.species_x_batch) # shape: [B, N_species, N_out]
            return out[:, species_idx, out_idx]
        return out[species_idx, out_idx]

    def forward_specie_fn(x_species_input):
        virtual_batch = x_species_input.size(0) // test_data.species_num_nodes
        # handle virtual batches generated by captum
        data_exp = Batch.from_data_list([test_data] * virtual_batch, follow_batch=['species_x', 'spatial_x']).to(device)

        data_exp.species_x = x_species_input[:, :data_exp.species_x.size(1)]
        data_exp.species_x_phylo = x_species_input[:, data_exp.species_x.size(1):]

        out = model(data_exp)
        return out
    
    x_species = torch.cat([test_data.species_x, test_data.species_x_phylo], axis=1).to(device)
    x_spatial = torch.cat([test_data.spatial_x, test_data.spatial_global_data], axis=1).to(device)
    ig_species = IntegratedGradients(forward_specie_fn)
    ig_space = IntegratedGradients(forward_space_fn)

    N_species = test_data.species_x.shape[0]
    F_spatial = x_spatial.shape[1]
    species_to_spatial = {}  # BACKWARD maps species -> list of spatial nodes
    spatial_to_species = test_data.spatial_species_edge_index.to(device)
    for i in range(spatial_to_species.shape[1]):
        i_spatial = spatial_to_species[0, i].item()
        i_species = spatial_to_species[1, i].item()
        species_to_spatial.setdefault(i_species, []).append(i_spatial)

    for out_idx in trange(len(dataset.y_index), leave=True, desc=f'Fold {k}'):

        x_species.requires_grad_()
        attributions_species = ig_species.attribute(inputs=x_species, target=out_idx)

        x_spatial.requires_grad_()
        attributions_spatial = torch.zeros((N_species, F_spatial), device=x_spatial.device)

        # Compute gradients per species node
        for s in trange(N_species, leave=False, desc='Species Attributions'):
            spatial_nodes = species_to_spatial.get(s, [])
            if not spatial_nodes:
                continue

            attr_spatial = ig_space.attribute(
                x_spatial, additional_forward_args=((s,), out_idx))
            
            attributions_spatial[s] = attr_spatial[spatial_nodes].sum(dim=0)  # Sum over all spatial nodes for this species


        attributions_species = pd.DataFrame(attributions_species.cpu().detach().numpy(),
                                index=test_species, columns=list(dataset.traits_all.columns) + [f'Phylo_{i}' for i in range(16)]
                            ).assign(dest_feature=dataset.traits_all.columns[dataset.y_index][out_idx], fold=k)
        attributions_species['Phylo'] = attributions_species.filter(like='Phylo').mean(axis=1)
        attributions_species = attributions_species.drop(columns=[f'Phylo_{i}' for i in range(16)])

        attributions_spatial = pd.DataFrame(attributions_spatial.cpu().detach().numpy(),
                                index=test_species, columns=space_cols
                            ).assign(dest_feature=dataset.traits_all.columns[dataset.y_index][out_idx], fold=k)
        attributions_spatial['Latitude'] = attributions_spatial.filter(like='lat').mean(axis=1)
        attributions_spatial['Longitude'] = attributions_spatial.filter(like='lon').mean(axis=1)
        attributions_spatial = attributions_spatial.drop(columns=['lat_1', 'lat_2', 'lon_1', 'lon_2'])
        Attr_Species = pd.concat([Attr_Species, attributions_species], axis=0)
        Attr_Spatial = pd.concat([Attr_Spatial, attributions_spatial], axis=0)

Attr_Species = Attr_Species.reset_index().rename(columns={'index': 'species'}).set_index(['species', 'dest_feature', 'fold'])
Attr_Spatial = Attr_Spatial.reset_index().rename(columns={'index': 'species'}).set_index(['species', 'dest_feature', 'fold'])
Attr_Species.to_csv(f'attributions_species_fold.csv', index=True)
Attr_Spatial.to_csv(f'attributions_spatial_fold.csv', index=True)